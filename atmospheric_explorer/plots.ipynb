{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atmospheric_explorer.cams_interfaces import InversionOptimisedGreenhouseGas\n",
    "from atmospheric_explorer.shapefile import ShapefilesDownloader\n",
    "from atmospheric_explorer.utils import get_local_folder\n",
    "from atmospheric_explorer.units_conversion import convert_units_array\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import rioxarray\n",
    "import plotly.graph_objects as go\n",
    "import shutil\n",
    "import numpy as np\n",
    "import statsmodels.stats.api as sms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous data\n",
    "shutil.rmtree(os.path.join(get_local_folder(), 'data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous data\n",
    "shutil.rmtree(os.path.join(get_local_folder(), 'shapefiles'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to move from 0+360 to -180+180 long\n",
    "def ds_swaplon(ds):\n",
    "    return ds.assign_coords(longitude=(((ds.longitude + 180) % 360) - 180)).sortby('longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = InversionOptimisedGreenhouseGas(\n",
    "    data_variables='carbon_dioxide',\n",
    "    file_format='zip',\n",
    "    quantity='surface_flux',\n",
    "    input_observations='surface',\n",
    "    time_aggregation='monthly_mean',\n",
    "    year=[\n",
    "        '1985', '1986', '1987',\n",
    "        '1988', '1989', '1990',\n",
    "        '1991', '1992', '1993',\n",
    "        '1994', '1995', '1996',\n",
    "        '1997', '1998', '1999',\n",
    "        '2000', '2001', '2002',\n",
    "        '2003', '2004', '2005',\n",
    "        '2006', '2007', '2008',\n",
    "        '2009', '2010', '2011',\n",
    "        '2012', '2013', '2014',\n",
    "        '2015', '2016', '2017',\n",
    "        '2018', '2019', '2020'\n",
    "    ],\n",
    "    month=[\n",
    "        '01', '02', '03',\n",
    "        '04', '05', '06',\n",
    "        '07', '08', '09',\n",
    "        '10', '11', '12'\n",
    "    ]\n",
    ")\n",
    "manager.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(list(glob(manager.file_full_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with first file\n",
    "mm = datetime.strptime(files[0].split('_')[-1].split('.')[0], '%Y%m')\n",
    "df = xr.open_dataset(files[0])[['flux_foss']]\n",
    "df = df.expand_dims({'time': [mm]})\n",
    "# Merge remaining files\n",
    "for file in files[1:]:\n",
    "    mm = datetime.strptime(file.split('_')[-1].split('.')[0], '%Y%m')\n",
    "    temp = xr.open_dataset(file)[['flux_foss']]\n",
    "    temp = temp.expand_dims({'time': [mm]})\n",
    "    df = xr.combine_by_coords([df, temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rio.write_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_down = ShapefilesDownloader(\n",
    "    resolution='10m',\n",
    "    instance='countries_ita'\n",
    ")\n",
    "sh_down.download_shapefile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = gpd.read_file(sh_down.shapefile_full_path, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clipped = df.rio.clip(sh[sh['ADMIN'] == 'Italy'].geometry.apply(mapping), sh.crs, drop=True)[['flux_foss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clipped['flux_foss'][0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all values that are null over all coords, compute the mean of the remining values over long and lat\n",
    "df_clipped = df_clipped.where(~df_clipped['flux_foss'].isnull(), drop=True).sortby('time').mean(dim=['longitude', 'latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool but not interactive\n",
    "sns.lineplot(\n",
    "    y=df_clipped['flux_foss'].values,\n",
    "    x=df_clipped.coords['time.year']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xarray doesn't cover all pandas functionalities, we need to convert it to a pandas dataframe\n",
    "df_pandas = df_clipped.to_pandas().reset_index()\n",
    "df_pandas['year'] = df_pandas['time'].dt.year\n",
    "df_pandas = df_pandas.groupby('year').agg(mean=('flux_foss', 'mean'), ci=('flux_foss', lambda d: sms.DescrStatsW(d).tconfint_mean()))\n",
    "df_pandas[['lower', 'upper']] = pd.DataFrame(df_pandas['ci'].to_list(), index=df_pandas.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly plot, it's interactive, some tweaking needed for the theme\n",
    "times = df_pandas.index.tolist()\n",
    "times_rev = times[::-1]\n",
    "\n",
    "# Line 1\n",
    "y1 = df_pandas['mean'].to_list()\n",
    "y1_upper = df_pandas['upper'].to_list()\n",
    "y1_lower = df_pandas['lower'].to_list()\n",
    "y1_lower = y1_lower[::-1]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=times+times_rev,\n",
    "    y=y1_upper+y1_lower,\n",
    "    fill='toself',\n",
    "    fillcolor='rgba(0,100,200,0.2)',\n",
    "    line_color='rgba(0,100,200,0.2)'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=times,\n",
    "    y=df_pandas['mean'].to_list(),\n",
    "    line_color='rgb(0,100,200)'\n",
    "))\n",
    "fig.update_traces(mode='lines')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "## 1 - Shiftare lat e long se necessario -> EAC4 va da 0 a 360, ma Inversion è già tra -180+180\n",
    "## 2 - Clip paese -> Capire se funziona, sembra funzionare\n",
    "## 3 - Media annuale -> In realtà ci dovrebbe essere un modo per calcolare il CI su plotly, basta avere diversi valori per anno\n",
    "##                    -> No, quella è seaborn, su plotly va fatto a mano usando ad esempio statsmodels\n",
    "## 4 - Plot con CI al 95% e aggiugere la seconda linea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmospheric-explorer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
